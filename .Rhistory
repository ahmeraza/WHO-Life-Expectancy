install.packages("ggplot2")
library(ggplot2)
p <- ggplot(mtcars, aes(wt, mpg))
p + geom_point(aes(size = qsec, colour = factor(cyl)))
install.packages("tidyverse")
install.packages("tinytex")
library(dplyr)
library(magrittr)
print(mtcars)
library(magrittr)
library(dplyr)
print(mtcars)
a <- filter(mtcars, carb>2)
b <- group_by(a, cyl)
c <- summarise(b, avg_mpg=mean(mpg))
c <- summarise(b, avg_mpg=mean(mpg) )
view(c)
View(c)
d <- filter(c, avg_mpg > 15)
z <- filter(
summarise(
group_by(
filter(
mtcars, carb>2
)
,cyl
),
avg_mpg = mean(mpg)
),
avg_mpg > 15)
piped_df <- mtcars %>%
filter(carb>2) %>%
group_by(cyl) %>%
summarise(avg_mpg = mean(mpg)) %>%
filter(avg_mpg > 15)
my_txt <- c("I think that data is the new bacon",
"what is more. I think that text analytics is the new turkey bacon",
"very few people know how good Canadian bacon is",
"and even fewer people know how a beaver tail tastes like",
"Putin french fries are not so good")
#install.packages("xxxxxx")
library(dplyr)
mydf <- data.frame(line=1:5, text=my_txt)
print(my_txt)
View(mydf)
View(mydf)
library(tidytext)
#install.packages("tidytext")
library(tidytext)
#install.packages("tidyverse")
######################################################
######## Step3: tokenizing the mydf dataframe#########
######################################################
#install.packages("tidytext")
#install.packages("tidyverse")
library(tidytext)
######################################################
######## Step3: tokenizing the mydf dataframe#########
######################################################
#install.packages("tidytext")
#install.packages("tidyverse")
library(tidytext)
######################################################
######## Step3: tokenizing the mydf dataframe#########
######################################################
#install.packages("tidytext")
install.packages("tidytext")
library(tidytext)
library(tidyverse)
token_list <- mydf %>%
unnest_tokens(word, text)
#no punctutation, no upper case letters
print(token_list)
frequencies_tokens <- mydf %>%
unnest_tokens(word,text) %>%
count(word, sort=TRUE)
print(frequencies_tokens)
install.packages("stringr")
library(stringr)
library(stringr)
data(stop_words)
frequencies_tokens_nostop <- mydf %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>% #here's where we remove tokens
count(word, sort=TRUE)
print(frequencies_tokens_nostop)
library(ggplot2)
freq_hist <- mydf %>%
unnest_token(word,text) %>%
anti_join(stop_words) %>%
count(word, sort=TRUE) %>%
mutate(word=reorder(word, n)) %>%
ggplot(aes(word, n))+
geom_col()+
xlab(NULL)+
coord_flip()
freq_hist <- mydf %>%
unnest_tokens(word,text) %>%
anti_join(stop_words) %>%
count(word, sort=TRUE) %>%
mutate(word=reorder(word, n)) %>%
ggplot(aes(word, n))+
geom_col()+
xlab(NULL)+
coord_flip()
print(freq_hist)
install.packages(tidytuesdayR)
install.packages("remotes")
install.packages("mongolite")
#need to run this line of code only once and then you can comment out
library(mongolite)
# This is the connection_string. You can get the exact url from your MongoDB cluster screen
#replace the <<user>> with your Mongo user name and <<password>> with the mongo password
#lastly, replace the <<server_name>> with your MongoDB server name
connection_string <- 'mongodb+srv://araza1:mopish9021@cluster1112.hxdx4.mongodb.net/?retryWrites=true&w=majority&appName=Cluster1112'
airbnb_collection <- mongo(collection="companies", db="sample_training", url=connection_string)
airbnb_all <- airbnb_collection$find()
company_all <- airbnb_collection$find()
print(company_all$overview[1])
print(company_all$overview[0])
print(company_all$overview[2])
# Loading required libraries
library(tidyverse)
library(countrycode)
# Reading the Male Life Expectancy dataset
df_males <- read.csv("data/Males.csv", skip=4, stringsAsFactors=FALSE, check.names=TRUE)
# Loading required libraries
library(tidyverse)
library(countrycode)
# Reading the Male Life Expectancy dataset
df_males <- read.csv("Males.csv", skip=4, stringsAsFactors=FALSE, check.names=TRUE)
# Reading the Female Life Expectancy dataset
df_females <- read.csv("Females.csv", skip=4, stringsAsFactors=FALSE, check.names=TRUE)
# To view column names
colnames(df_males)
colnames(df_females)
# Removing unnecessary columns
df_males <- df_males %>%
select(-c(Indicator.Name, Indicator.Code, X, X2023))
df_females <- df_females %>%
select(-c(Indicator.Name, Indicator.Code, X, X2023))
# Renaming columns to remove 'X' prefix from each year
colnames(df_males) <- gsub("^X", "", colnames(df_males))
colnames(df_females) <- gsub("^X", "", colnames(df_females))
# To view column names after cleaning
colnames(df_males)
colnames(df_females)
# Histogram Plots for Males & Females
hist(df_males %>% select(where(is.numeric)) %>% unlist(),
main = "Distribution of Life Expectancy (Males)",
xlab = "Life Expectancy", col = "blue", breaks =30)
hist(df_females %>% select(where(is.numeric)) %>% unlist(),
main = "Distribution of Life Expectancy (Females)",
xlab = "Life Expectancy", col = "red", breaks = 30)
# Replacing the missing values with the median life expectancy for each country
df_males <- df_males %>%
group_by(Country.Name) %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
ungroup()
df_females <- df_females %>%
group_by(Country.Name) %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
ungroup()
# In order to handle any remaining NAs with the global median for each year
df_males <- df_males %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
df_females <- df_females %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
# Verifying if all the missing values were removed
sum(is.na(df_males))
sum(is.na(df_females))
# Converting Males dataset to long format
df_males_long <- df_males %>%
pivot_longer(cols = where(is.numeric),
names_to = "Year",
values_to = "Life_Expectancy_Male")
# Converting Females dataset to long format
df_females_long <- df_females %>%
pivot_longer(cols = where(is.numeric),
names_to = "Year",
values_to = "Life_Expectancy_Female")
# Converting the Year column to numeric
df_males_long$Year <- as.numeric(df_males_long$Year)
df_females_long$Year <- as.numeric(df_females_long$Year)
# Checking to see whether the transformation was successful
head(df_males_long)
head(df_females_long)
# Merging the Males and Females datasets by Country, Country Code, and Year
df_combined <- merge(df_males_long, df_females_long, by = c("Country.Name", "Country.Code", "Year"))
# Checking to see if the merge was successful
head(df_combined)
# Adding Continent information based on Country Code
df_combined$Continent <- countrycode(df_combined$Country.Code, "iso3c", "continent")
# Verifying whether the continents were assigned properly
head(df_combined)
# Saving the cleaned and merged dataset
write.csv(df_combined, "data/Merged_Life_Expectancy.csv", row.names = FALSE)
# Saving the cleaned and merged dataset
write.csv(df_combined, "Merged_Life_Expectancy.csv", row.names = FALSE)
# Checking basic summary statistics
summary(df_combined)
# Verifying if there are any remaining missing values
sum(is.na(df_combined))
# Checking to see which columns have missing values
colSums(is.na(df_combined))
# Seeing which countries do not have a continent assigned yet
df_missing_continent <- df_combined %>% filter(is.na(Continent)) %>% select(Country.Name, Country.Code) %>% distinct()
print(df_missing_continent)
# Replacing the missing continent values with "Unclassifed"
df_combined$Continent[is.na(df_combined$Continent)] <- "Unclassifed"
# Verifying whether all the missing values were handled
sum(is.na(df_combined$Continent))
# Checking the count of all the regions
table(df_combined$Continent)
library(extrafont)
font_import()
